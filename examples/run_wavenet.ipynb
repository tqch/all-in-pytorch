{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data import TinyVCTK\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from utils import load_configs, NucleusSampler\n",
    "from train import train\n",
    "from models.wavenet import WaveNet\n",
    "\n",
    "configs = load_configs(\"../configs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/30 epochs: 100%|██████████| 205/205 [09:59<00:00,  2.92s/it, train_loss=3.45, test_loss=2.78] \n",
      "2/30 epochs: 100%|██████████| 205/205 [09:54<00:00,  2.90s/it, train_loss=2.74, test_loss=2.59] \n",
      "3/30 epochs: 100%|██████████| 205/205 [09:53<00:00,  2.89s/it, train_loss=2.61, test_loss=2.52] \n",
      "4/30 epochs: 100%|██████████| 205/205 [09:56<00:00,  2.91s/it, train_loss=2.54, test_loss=2.47] \n",
      "5/30 epochs: 100%|██████████| 205/205 [09:53<00:00,  2.90s/it, train_loss=2.51, test_loss=2.43] \n",
      "6/30 epochs: 100%|██████████| 205/205 [09:56<00:00,  2.91s/it, train_loss=2.47, test_loss=2.41] \n",
      "7/30 epochs: 100%|██████████| 205/205 [09:56<00:00,  2.91s/it, train_loss=2.45, test_loss=2.39] \n",
      "8/30 epochs: 100%|██████████| 205/205 [09:54<00:00,  2.90s/it, train_loss=2.43, test_loss=2.37] \n",
      "9/30 epochs: 100%|██████████| 205/205 [09:57<00:00,  2.91s/it, train_loss=2.41, test_loss=2.35] \n",
      "10/30 epochs: 100%|██████████| 205/205 [09:59<00:00,  2.93s/it, train_loss=2.4, test_loss=2.34] \n",
      "11/30 epochs: 100%|██████████| 205/205 [09:59<00:00,  2.93s/it, train_loss=2.38, test_loss=2.32] \n",
      "12/30 epochs: 100%|██████████| 205/205 [09:56<00:00,  2.91s/it, train_loss=2.37, test_loss=2.32] \n",
      "13/30 epochs: 100%|██████████| 205/205 [10:00<00:00,  2.93s/it, train_loss=2.36, test_loss=2.3] \n",
      "14/30 epochs: 100%|██████████| 205/205 [10:02<00:00,  2.94s/it, train_loss=2.35, test_loss=2.29] \n",
      "15/30 epochs: 100%|██████████| 205/205 [10:06<00:00,  2.96s/it, train_loss=2.33, test_loss=2.28] \n",
      "16/30 epochs: 100%|██████████| 205/205 [10:07<00:00,  2.96s/it, train_loss=2.33, test_loss=2.27] \n",
      "17/30 epochs: 100%|██████████| 205/205 [10:04<00:00,  2.95s/it, train_loss=2.31, test_loss=2.27] \n",
      "18/30 epochs: 100%|██████████| 205/205 [09:57<00:00,  2.91s/it, train_loss=2.31, test_loss=2.25] \n",
      "19/30 epochs: 100%|██████████| 205/205 [10:00<00:00,  2.93s/it, train_loss=2.3, test_loss=2.24] \n",
      "20/30 epochs: 100%|██████████| 205/205 [10:00<00:00,  2.93s/it, train_loss=2.29, test_loss=2.23] \n",
      "21/30 epochs: 100%|██████████| 205/205 [10:04<00:00,  2.95s/it, train_loss=2.28, test_loss=2.22] \n",
      "22/30 epochs: 100%|██████████| 205/205 [10:07<00:00,  2.96s/it, train_loss=2.27, test_loss=2.21] \n",
      "23/30 epochs: 100%|██████████| 205/205 [10:06<00:00,  2.96s/it, train_loss=2.26, test_loss=2.21] \n",
      "24/30 epochs: 100%|██████████| 205/205 [10:02<00:00,  2.94s/it, train_loss=2.25, test_loss=2.2] \n",
      "25/30 epochs: 100%|██████████| 205/205 [10:06<00:00,  2.96s/it, train_loss=2.25, test_loss=2.19] \n",
      "26/30 epochs: 100%|██████████| 205/205 [10:06<00:00,  2.96s/it, train_loss=2.22, test_loss=2.17] \n",
      "27/30 epochs: 100%|██████████| 205/205 [10:04<00:00,  2.95s/it, train_loss=2.22, test_loss=2.17] \n",
      "28/30 epochs: 100%|██████████| 205/205 [10:06<00:00,  2.96s/it, train_loss=2.22, test_loss=2.17] \n",
      "29/30 epochs: 100%|██████████| 205/205 [10:06<00:00,  2.96s/it, train_loss=2.22, test_loss=2.17] \n",
      "30/30 epochs: 100%|██████████| 205/205 [10:03<00:00,  2.94s/it, train_loss=2.22, test_loss=2.17] \n"
     ]
    }
   ],
   "source": [
    "sampler = NucleusSampler(threshold=1.0)  # degenerate to standard temperature(=1) sampling\n",
    "\n",
    "model = WaveNet(\n",
    "    input_dim=256,\n",
    "    hidden_dim=32,\n",
    "    skip_dim=256,\n",
    "    kernel_size=2,\n",
    "    layers_per_block=10,\n",
    "    num_blocks=5,\n",
    "    quantization=True,\n",
    "    padding_mode=\"learnable\",\n",
    "    sampler=sampler\n",
    ")\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "epochs = 30\n",
    "batch_size = 8\n",
    "num_batches_eval = 10\n",
    "start_length = 8000\n",
    "\n",
    "root = configs[\"dataset_path\"]\n",
    "\n",
    "def loss_fn(xhat, x):\n",
    "    return F.cross_entropy(xhat[:, :, :-1], x[:, 1:].long(), ignore_index=-1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# considering the computational cost and our purpose of generating human-like voice\n",
    "# we will use real audios as seeds and train our model on the testset (sample size is smaller)\n",
    "trainset = TinyVCTK.load_default(root=configs[\"dataset_path\"], train=False)\n",
    "testset = TinyVCTK.load_default(root=configs[\"dataset_path\"], train=False)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "preprocessing = None\n",
    "postprocessing = trainset.transform.mu_law_decode\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    epochs,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    scheduler=scheduler,\n",
    "    data_type=\"audio\",\n",
    "    preprocessing=preprocessing,\n",
    "    postprocessing=postprocessing,\n",
    "    additional_eval=None,\n",
    "    num_batches_eval=num_batches_eval,\n",
    "    index_type=None,\n",
    "    save_dir=\"..\",\n",
    "    sampling_rate=16000,\n",
    "    start_length=start_length,\n",
    "    generate_length=24000,\n",
    "    n_tracks=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
